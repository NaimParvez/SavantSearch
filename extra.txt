for page in range(1, max_pages + 1):
    st.write(f"Processing page {page} for '{query}'...")
    url = f"https://www.ebay.com/sch/i.html?_nkw={query.replace(' ', '+')}&_pgn={page}"
    
    try:
        response = scraper.session.get(url, headers=scraper.headers)
        response.raise_for_status() # Raise an error for bad responses (4xx or 5xx)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # --- MODIFIED SECTION START ---

        # The new selector for each product item container
        listings = soup.select('li.s-item')
        
        if not listings:
            st.write(f"No listings found on page {page} for '{query}'. This might be the last page.")
            break # Exit if no items are found on the page

        for listing in listings:
            # Skip promotional/non-product items
            if listing.select_one('.s-item__title') is None:
                continue
            
            # Find elements within the new listing container
            title_elem = listing.select_one('.s-item__title')
            price_elem = listing.select_one('.s-item__price')
            link_elem = listing.select_one('a.s-item__link')
            
            title_text = title_elem.text.strip() if title_elem else "N/A"
            
            # Exclude common non-product titles
            if "Shop on eBay" in title_text or title_text == "N/A":
                continue

            if title_elem and price_elem and link_elem:
                products.append({
                    'title': title_text,
                    'price': price_elem.text.strip(),
                    'link': link_elem.get('href'),
                    'search_query': query
                